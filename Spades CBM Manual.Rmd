--- 
title: "Spades CBM Manual"
author: "John Doe"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::bs4_book,
  set in the _output.yml file.
biblio-style: apalike
csl: chicago-fullnote-bibliography.csl
---
```{r include=FALSE, cache=FALSE}
pkgPath <- file.path("packages", version$platform,
                     paste0(version$major, ".", strsplit(version$minor, "[.]")[[1]][1]))
.libPaths(pkgPath)   ## need to include.side = TRUE to use bookdown and rmarkdown

# example R options set globally
options("width" = 60
        , repos = c(CRAN = "https://cran.rstudio.com")
        )

## knitr-related options
options(knitr.table.format = function() {
  if (knitr::is_latex_output())
    "latex" else "pipe"
})

options("knitr.graphics.rel_path" = FALSE)

rm(list = ls(all.names = TRUE))

# options(bookdown.post.latex = function(x) {
#   # substitute nonbreaking spaces in \texttt{} with normal spaces
#   m = gregexpr('\\\\texttt\\{[^}]+}', x)
#   regmatches(x, m) = lapply(regmatches(x, m), function(z) {
#     gsub('\\\\ ', ' ', z)
#   })
#   # only build a skeleton for the online version
#   if (Sys.getenv('BOOKDOWN_FULL_PDF', '') == 'false') return(bookdown:::strip_latex_body(
#     x, '\nThis PDF is only a skeleton. Please either read the free online HTML version, or purchase a hard-copy of this book.\n'
#   ))
#   # fix syntax highlighting:
#   # \FunctionTok{tufte:}\AttributeTok{:tufte_html: default} ->
#   # \FunctionTok{tufte::tufte_html:}\AttributeTok{ default}
#   x = gsub('(\\\\AttributeTok\\{[^:]+:)(})(\\\\FunctionTok\\{)(:[^:]+:)', '\\1\\4\\2\\3', x)
#   if (length(i <- grep('^\\\\begin\\{longtable\\}', x)) == 0) return(x)
#   i1 = bookdown:::next_nearest(i, which(x == '\\toprule'))
#   i2 = bookdown:::next_nearest(i, which(x == '\\endfirsthead'))
#   x[i1 - 1] = paste0(x[i1 - 1], '\n\\begin{tabular}{', gsub('[^lcr]', '', gsub('.*\\[]', '', x[i])), '}')
#   x[i] = '\\begin{table}'
#   x[x == '\\end{longtable}'] = '\\end{tabular}\n\\end{table}'
#   x[x == '\\endhead'] = ''
#   x = x[-unlist(mapply(seq, i1, i2, SIMPLIFY = FALSE))]
#   x
# })

# chunk options set globally
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60),
  size = "tiny",
  fig.pos = "H",
  out.extra = ""
)



```

# About

This is a _sample_ book written in **Markdown**. You can use anything that Pandoc's Markdown supports; for example, a math equation $a^2 + b^2 = c^2$.

## Usage 

Each **bookdown** chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter *must* start with a first-level heading: `# A good chapter`, and can contain one (and only one) first-level heading.

Use second-level and higher headings within chapters like: `## A short section` or `### An even shorter section`.

The `index.Rmd` file is required, and is also your first book chapter. It will be the homepage when you render the book.

## Render book

You can render the HTML version of this example book without changing anything:

1. Find the **Build** pane in the RStudio IDE, and

1. Click on **Build Book**, then select your output format, or select "All formats" if you'd like to use multiple formats from the same book source files.

Or build the book from the R console:

```{r, eval=FALSE}
bookdown::render_book()
```

To render this example to PDF as a `bookdown::pdf_book`, you'll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): <https://yihui.org/tinytex/>.

## Preview book

As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in "Preview book", or from the R console:

```{r eval=FALSE}
bookdown::serve_book()
```


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.rmd-->

---
title: "CBM_defaults"
author: ""
date: "19 January 2018"
output: pdf_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
pkgPath <- file.path("packages", version$platform,
                     paste0(version$major, ".", strsplit(version$minor, "[.]")[[1]][1]))
.libPaths(pkgPath)   ## need to include.side = TRUE to use bookdown and rmarkdown

# example R options set globally
options("width" = 60
        , repos = c(CRAN = "https://cran.rstudio.com")
        )

## knitr-related options
options(knitr.table.format = function() {
  if (knitr::is_latex_output())
    "latex" else "pipe"
})

options("knitr.graphics.rel_path" = FALSE)

rm(list = ls(all.names = TRUE))

# options(bookdown.post.latex = function(x) {
#   # substitute nonbreaking spaces in \texttt{} with normal spaces
#   m = gregexpr('\\\\texttt\\{[^}]+}', x)
#   regmatches(x, m) = lapply(regmatches(x, m), function(z) {
#     gsub('\\\\ ', ' ', z)
#   })
#   # only build a skeleton for the online version
#   if (Sys.getenv('BOOKDOWN_FULL_PDF', '') == 'false') return(bookdown:::strip_latex_body(
#     x, '\nThis PDF is only a skeleton. Please either read the free online HTML version, or purchase a hard-copy of this book.\n'
#   ))
#   # fix syntax highlighting:
#   # \FunctionTok{tufte:}\AttributeTok{:tufte_html: default} ->
#   # \FunctionTok{tufte::tufte_html:}\AttributeTok{ default}
#   x = gsub('(\\\\AttributeTok\\{[^:]+:)(})(\\\\FunctionTok\\{)(:[^:]+:)', '\\1\\4\\2\\3', x)
#   if (length(i <- grep('^\\\\begin\\{longtable\\}', x)) == 0) return(x)
#   i1 = bookdown:::next_nearest(i, which(x == '\\toprule'))
#   i2 = bookdown:::next_nearest(i, which(x == '\\endfirsthead'))
#   x[i1 - 1] = paste0(x[i1 - 1], '\n\\begin{tabular}{', gsub('[^lcr]', '', gsub('.*\\[]', '', x[i])), '}')
#   x[i] = '\\begin{table}'
#   x[x == '\\end{longtable}'] = '\\end{tabular}\n\\end{table}'
#   x[x == '\\endhead'] = ''
#   x = x[-unlist(mapply(seq, i1, i2, SIMPLIFY = FALSE))]
#   x
# })

# chunk options set globally
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60),
  size = "tiny",
  fig.pos = "H",
  out.extra = ""
)



```

# Overview

This module can run independently by running the global script below.
Its main task is to read-in all the default values in SpaDES-CBM which is akin to the `ArchiveIndex` in CBM-CFS3 runs.

# Usage

```{r module_deafults_usage, eval=FALSE}
if (!require("remotes")) {
  install.packages("remotes")
}
remotes::install_github("PredictiveEcology/Require@development")
remotes::install_github("PredictiveEcology/CBMutils@development")
library(Require)
Require("PredictiveEcology/SpaDES.project@transition", require = FALSE)
Require(c("SpaDES.core (>=1.1.0)", "SpaDES.tools (>= 1.0.0)",
          "googledrive", 'RCurl', 'XML'),
          #unlist(unname(packagesNeededInModules))),
        require = "SpaDES.core", # call `require` only on this package (same as `library`)
        verbose = 1)

cacheDir <- reproducible::checkPath("cache", create = TRUE)
moduleDir <- "modules"
inputDir <- reproducible::checkPath("inputs", create = TRUE)
outputDir <- reproducible::checkPath("outputs", create = TRUE)
setPaths(inputPath = inputDir, 
         modulePath = moduleDir, 
         outputPath = outputDir, 
         cachePath = cacheDir)

times <- list(start = 0, end = 10)
parameters <- list(
  #.progress = list(type = "text", interval = 1), # for a progress bar
  ## If there are further modules, each can have its own set of parameters:
  #module1 = list(param1 = value1, param2 = value2),
  #module2 = list(param1 = value1, param2 = value2)
)
modules <- list("CBM_defaults")
objects <- list()
paths <- list(
  cachePath = cacheDir,
  modulePath = moduleDir,
  inputPath = inputDir,
  outputPath = outputDir
)

myDefaults <- simInit(times = times, params = parameters, modules = modules,
                      objects = objects, paths = paths)

outDefaults <- spades(myDefaults)
```

```{r tests, eval=FALSE}
# The spades call should make a "dataset" class object
testthat::expect_true(is(outSim@.envir$cbmData, "dataset"))
```

# Events

Describe what happens for each event type.

## Plotting

Write what is plotted.

## Saving

Write what is saved.

# Data dependencies

## Input data

How to obtain input data, and a description of the data required by the module.
If `sourceURL` is specified, `downloadData("CBM_defaults", "path/to/modules/dir")` may be sufficient.

## Output data

Description of the module outputs.

# Links to other modules

Describe any anticipated linkages to other modules.


<!--chapter:end:modules//CBM_defaults/CBM_defaults.Rmd-->

---
title: "CBM_dataPrep_SK"
author:
  - Celine Boisvenue
  - Alex Chubaty
date: "September 2021"
output:
  html_document:
    keep_md: yes
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: sentence
---
```{r include=FALSE, cache=FALSE}
pkgPath <- file.path("packages", version$platform,
                     paste0(version$major, ".", strsplit(version$minor, "[.]")[[1]][1]))
.libPaths(pkgPath)   ## need to include.side = TRUE to use bookdown and rmarkdown

# example R options set globally
options("width" = 60
        , repos = c(CRAN = "https://cran.rstudio.com")
        )

## knitr-related options
options(knitr.table.format = function() {
  if (knitr::is_latex_output())
    "latex" else "pipe"
})

options("knitr.graphics.rel_path" = FALSE)

rm(list = ls(all.names = TRUE))

# options(bookdown.post.latex = function(x) {
#   # substitute nonbreaking spaces in \texttt{} with normal spaces
#   m = gregexpr('\\\\texttt\\{[^}]+}', x)
#   regmatches(x, m) = lapply(regmatches(x, m), function(z) {
#     gsub('\\\\ ', ' ', z)
#   })
#   # only build a skeleton for the online version
#   if (Sys.getenv('BOOKDOWN_FULL_PDF', '') == 'false') return(bookdown:::strip_latex_body(
#     x, '\nThis PDF is only a skeleton. Please either read the free online HTML version, or purchase a hard-copy of this book.\n'
#   ))
#   # fix syntax highlighting:
#   # \FunctionTok{tufte:}\AttributeTok{:tufte_html: default} ->
#   # \FunctionTok{tufte::tufte_html:}\AttributeTok{ default}
#   x = gsub('(\\\\AttributeTok\\{[^:]+:)(})(\\\\FunctionTok\\{)(:[^:]+:)', '\\1\\4\\2\\3', x)
#   if (length(i <- grep('^\\\\begin\\{longtable\\}', x)) == 0) return(x)
#   i1 = bookdown:::next_nearest(i, which(x == '\\toprule'))
#   i2 = bookdown:::next_nearest(i, which(x == '\\endfirsthead'))
#   x[i1 - 1] = paste0(x[i1 - 1], '\n\\begin{tabular}{', gsub('[^lcr]', '', gsub('.*\\[]', '', x[i])), '}')
#   x[i] = '\\begin{table}'
#   x[x == '\\end{longtable}'] = '\\end{tabular}\n\\end{table}'
#   x[x == '\\endhead'] = ''
#   x = x[-unlist(mapply(seq, i1, i2, SIMPLIFY = FALSE))]
#   x
# })

# chunk options set globally
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60),
  size = "tiny",
  fig.pos = "H",
  out.extra = ""
)



```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE, results = "hold")
```

# Overview

This module is to read-in user-provided information or provide defaults.
It reads-in rasters (`ageRaster`, `ecoRaster`, `gcIndexRaster`, `spuRaster`, and `masterRaster`) from either defaults of provided by the user.
From the rasters, `pixelGroup` are created which are unique combinations of the rasters values.
`pixelGroup` is a main processing unit in SpaDES `CBM` simulations.
In a first step, a `spatialDT` which is a `data.table` listing all pixels with their respective values of `raster`, `pixelIndex` and `pixelGroup` is created (`sim$spatialDT`).
From the `spatialDT`, a reduced `data.table` is create (`sim$level3DT`) which is the data.table from which processing will start in `CBM_core`.
The number of records in this data.table (`sim$level3DT`) should equal the number of pixel groups that will be processed in the spinup event of the `CBM_core` module.
This present module also creates variables of the same length as the rows in `level3DT` for use in other events of the `CBM_core` module.
These are: `returnIntervals`, `maxRotations`, `minRotations`, `lastPassDMIDs`, `historicDMIDs`, and delays all stored in the `simList.`

Another important object created in this module is `mySpuDmids`.
This `data.table` links the user-defined disturbances (`$userDist`) with a spatial unit and a disturbance matrix.
This will be used to apply disturbances to pixel groups in the annual event of the `CBM_core` module.
The `mySpuDmids` object is created starting from a user provided list of disturbances (`userDist`) that matches the `rasterId` of the disturbance raster to the disturbance name, and speficies if the disturbance is stand-replacing (`userDist$wholeStand == 1`) or not (`userDist$wholeStand == 1`).
The disturbance names (`userDist$distName`) and their location of the disturbance (linked via the rasterID to the `sim$mySpuDmids$spatial_unit id`) are used to associate a disturbance matrix identification number to the disturbed `pixelGroup`.
Disturbance Matrices (DM) determine what proportion of a carbon pool gets transferred to another carbon pool via disturbance.
There are 426 matrix IDs in the present default data (`sim$processes$disturbanceMatrices`).
DMIDs (Disturbance Matrix IDs) are part of the default data of CBM-CFS3.
DMs are specific to spatial units which are a numbering (48 of them `sim$cbmData@spatialUnitIds`) of the overlay of the administrative boundaries and ecozones in Canada.
Spatial units are central units in CBM-CFS3, as are ecozones because both determining various ecological and other parameters that will be used in simulations via the `CBM_core` module.
The proportion of carbon transferred by a specific DMID can be found here `sim$cbmData@disturbanceMatrixValues`.
A series of R-functions were built to help users associate the correct disturbance matrices (`spuDist()`, `mySpu()`, `seeDist()`, `simDist()`) and are searchable in this package.

Note: \* CBM_defaults objects are recreated in the `.inputObject` of this module \* nothing is in carbon or carbon increments at this point.
This module feeds into the CBM_core module as does the CBM_vol2biomass.R module.

# Usage

```{r module_dataprep_usage, eval=FALSE}
library(igraph)
library(SpaDES.core)

moduleDir <- getwd()
inputDir <- file.path(moduleDir, "inputs") %>% reproducible::checkPath(create = TRUE)
outputDir <- file.path(moduleDir, "outputs")
cacheDir <- file.path(outputDir, "cache")
times <- list(start = 0, end = 10)
parameters <- list(
  #CBM_dataPrep = list(.useCache = ".inputObjects")
 #.progress = list(type = "text", interval = 1), # for a progress bar
 ## If there are further modules, each can have its own set of parameters:
 #module1 = list(param1 = value1, param2 = value2),
 #module2 = list(param1 = value1, param2 = value2)
 )
modules <- list("CBM_dataPrep_SK")
objects <- list(
  userDistFile = file.path(moduleDir, "CBM_dataPrep_SK", "data", "userDist.csv")
)
paths <- list(
  cachePath = cacheDir,
  modulePath = moduleDir,
  inputPath = inputDir,
  outputPath = outputDir
)

myInputs <- simInit(times = times, params = parameters, modules = modules,
                    objects = objects, paths = paths)

outInputs <- spades(myInputs)
```

# Events

There is only when event (init) is this module.

# Data dependencies

## Module parameters

```{r moduleParams, echo = FALSE, eval = FALSE}
df_params <- SpaDES.core::moduleParams("CBM_dataPrep_SK", "..")
knitr::kable(df_params)
```

## Input data

```{r moduleInputs, echo = FALSE, eval = FALSE}
df_inputs <- SpaDES.core::moduleInputs("CBM_dataPrep_SK", "..")
knitr::kable(df_inputs)
```

An example with all the user-provided rasters and `.csv` files is provided by default.
The example simulates a region of the managed forests of SK.
All rasters and data frames for this example are on a cloud-drive (`userDefaultData_CBM_SK`).
Unless using this example, the user most provide:

-   a raster of the study area at the desired resolution for simulation (`sim$masterRaster`)
-   an age raster (`sim$ageRaster`)
-   a raster indicating which growth curve should be applied to which pixels (`sim$gcIndexRaster`) or a URL for this raster (`sim$gcIndexRasterURL`).
-   raster of disturbances for each year the user wants disturbances to be simulated. This information could come from other SpaDES modules (fireSence, other fire modules, insects modules, etc.). For retrospective simulation (past to present), rasters found here can be used anywhere in Canada <https://opendata.nfis.org/downloads/forest_change/CA_forest_harvest_mask_year_1985_2015.zip>.
-   a `.csv` file of the growth curve for the study area (with links to the `sim$gcIndexRaster`), `sim$userGcM3.csv` or the location of this file (`sim$userGcM3File`). The `sim$userGcM3.csv` file is required to have three columns:
    -   "GrowthCurveComponentID", which will be the link to the raster `sim$gcIndexRaster`,
    -   "Age" ranging from 0 to the maximum age of the growth curve, and
    -   "MerchVolume" which is the cumulative value of m3/ha at each age along each growth curve.
-   a file with the disturbances to be applied as well as their raster values (`sim$userDist`) or its location (`sim$userDistFile`). The `userDist.csv` file must have three columns:
    -   "distName" representing a simple description of the disturbance type (e.g., fire, clearcut, deforestation, etc.).
    -   "rasterId" which indications the value that this specific disturbance will have on the disturbance raster.
    -   "wholeStand" indicating if the disturbance is stand-replacing disturbance (1) or a partial disturbance (0).

The user could provide: \* a raster of the ecozones in their study area (`sim$ecoRaster`), but the script will calculate this raster based on the `sim$masterRaster` if it is not provided.
\* a raster of the spatial units (`sim$spuRaster`) but the script will calculate this raster based on the `sim$masterRaster` if it is not provided.

## Output data

```{r moduleOutputs, echo = FALSE, eval = FALSE}
df_outputs <- SpaDES.core::moduleOutputs("CBM_dataPrep_SK", "..")
knitr::kable(df_outputs)
```

# Links to other modules

-   [`CBM_core`](https://github.com/PredictiveEcology/CBM_core)
-   [`CBM_defaults`](https://github.com/PredictiveEcology/CBM_defaults)
-   [`CBM_vol2biomass`](https://github.com/PredictiveEcology/CBM_vol2biomass)

<!--chapter:end:modules/CBM_dataPrep_SK/CBM_dataPrep_SK.Rmd-->

---
title: "CBM_vol2biomass"
author:
  - Celine Boisvenue
  - Alex Chubaty
date: "14 May 2020"
output: pdf_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
pkgPath <- file.path("packages", version$platform,
                     paste0(version$major, ".", strsplit(version$minor, "[.]")[[1]][1]))
.libPaths(pkgPath)   ## need to include.side = TRUE to use bookdown and rmarkdown

# example R options set globally
options("width" = 60
        , repos = c(CRAN = "https://cran.rstudio.com")
        )

## knitr-related options
options(knitr.table.format = function() {
  if (knitr::is_latex_output())
    "latex" else "pipe"
})

options("knitr.graphics.rel_path" = FALSE)

rm(list = ls(all.names = TRUE))

# options(bookdown.post.latex = function(x) {
#   # substitute nonbreaking spaces in \texttt{} with normal spaces
#   m = gregexpr('\\\\texttt\\{[^}]+}', x)
#   regmatches(x, m) = lapply(regmatches(x, m), function(z) {
#     gsub('\\\\ ', ' ', z)
#   })
#   # only build a skeleton for the online version
#   if (Sys.getenv('BOOKDOWN_FULL_PDF', '') == 'false') return(bookdown:::strip_latex_body(
#     x, '\nThis PDF is only a skeleton. Please either read the free online HTML version, or purchase a hard-copy of this book.\n'
#   ))
#   # fix syntax highlighting:
#   # \FunctionTok{tufte:}\AttributeTok{:tufte_html: default} ->
#   # \FunctionTok{tufte::tufte_html:}\AttributeTok{ default}
#   x = gsub('(\\\\AttributeTok\\{[^:]+:)(})(\\\\FunctionTok\\{)(:[^:]+:)', '\\1\\4\\2\\3', x)
#   if (length(i <- grep('^\\\\begin\\{longtable\\}', x)) == 0) return(x)
#   i1 = bookdown:::next_nearest(i, which(x == '\\toprule'))
#   i2 = bookdown:::next_nearest(i, which(x == '\\endfirsthead'))
#   x[i1 - 1] = paste0(x[i1 - 1], '\n\\begin{tabular}{', gsub('[^lcr]', '', gsub('.*\\[]', '', x[i])), '}')
#   x[i] = '\\begin{table}'
#   x[x == '\\end{longtable}'] = '\\end{tabular}\n\\end{table}'
#   x[x == '\\endhead'] = ''
#   x = x[-unlist(mapply(seq, i1, i2, SIMPLIFY = FALSE))]
#   x
# })

# chunk options set globally
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60),
  size = "tiny",
  fig.pos = "H",
  out.extra = ""
)



```

<!-- TODO: cleanup and format this file
     * one sentence per line
     * use backticks for code formatting
     * remane modules!
-->

# Overview

This module translates the m3/ha values into the biomass/ha increments that spadesCBMcore needs to simulate annual carbon fluxes and estimate stocks in the spadesCBMcore.R module of the spadesCBM. This is an implementation of the Boudewyn et al 2007 stand-level translation. Like many statistical models, this translation is not always successful. This scripts is in line with the translation procedure in CBM-CFS3 with the addition of smoothing methods using Generalized Additive Models (GAMs). This module provides two examples of smoothing methods: one applied to the cumulative carbon/ha curves (merch, foliage, and other for each growth curves provided), and one applied to the increment curves (differences betwee years of the cumulative curves). **It is the responsibility of the user to decide if these curves and smoothing methods are appropriate.** This module can be run independently of the spadesCBM deck of SpaDES modules.

## User input

The user must provide two files for the growth information and one location file. Note that these can be provided in the spadesCBMinputs module if the spadesCBM deck is used: 
* one metadata file (userGcMeta) that has at a minimum an identifier that links each specific growth curve to a pixel on the study area raster (gcId - growth curve identification number) and the leading species for that curve.
* one file that gives the m3 per ha by age for each of the identified growth curves. 
* a location information file. This information is preferably passed along as a raster from the spadesCBMinputs module, but that can be by-passed by providing a vector of the ecozones and spatial units the growth curves apply to. The information is used to identify the jurisdiction (province or territory) and the ecozone each gcId is in, which in turn are used to determine the appropriate parameters for the stand-level conversion from m3/ha to biomass per ha in the Boudewyn et al. approach.

## Default files provided

Two types of information are built in to this module: Boudewyn et al. parameters tables, and data frames to help link CBM-specific information and parameter categories. 
* URLs to the Boudewyn et al. five parameter tables are built into this module (see .inputObjects) and will be loaded from the NFIS site directly.
* the cbmAdmin data frame links CBM-specific spatial units to administrative boundaries in Canada and ecozones.
* the canfi_species data frame provides the canfi_species numbers and genus abbreviations used to identify the correct parameters in Boudewyn et al tables. This also specifies a name for each tree species and the forest_type_id, which is an identifier used in CBM.

## Pseudocode: the general steps

This module reads in the user userGcMeta, then reads in the userGcM3. It provides a plot of all the curves in userGcM3 for visual inspection (`sim$volCurves`). It then matches the jurisdiction with each gcId (growth curve identification), and matches the leading species attaching a canfi_species (number) and a genus to each leading species. canfi_species and genus are key to associating the correct parameters for conversion (Boudewyn et al. 2007). Once all the species matches are complete, a series of functions (see the package `CBMutils`) are used to go from the provided cumulative m3/ha for each curve into cumulative tonnes of carbon/ha for each above ground live biomass pool (merch, foliage, other). A visual check is provided via `sim$plotsRawCumulativeBiomass`. Since most of the time these models need smoothing, two examples of smoothing, applied to the Saskatchewan default example, are provided by fitting GAMs to 1) each of the cumulative curve (per gcId) for each three pool, and 2) fitting GAMs to the increments between years for each of the three pools. Currently, example 1) is commented out, and example 2) is used to show that sometimes, even perfect-looking curves need hard fixes. In these examplee, the default knots for the GAMs are set at 20 (k=20) and extra weight is given to the 0 intercept and the maximum value of each curve by setting weights (wts in the script). See http://environmentalcomputing.net/intro-to-gams/ for an guide to GAMs. Again, **it is the user's responsibility to decided if smoothing parameters and/or methods are appropriate**. In the default example 1) (commented out), fitted values of the GAMs to the cumulative curves of carbon/ha  are used to calculate annual increment, which are then dived by two for use in the spadesCBMcore.R module annual processing (half the growth is processes in two instances). Halved increments can be visually assessed using `sim$checkInc` and the halved increments themselves are save in the simList (`sim$growth_increments`). In example 2), currently executed for the default Saskatchewan example, the increments are calculated prior to fitting the GAMs. In a final step (both examples), the halved growth increment table if hashed for processing speed (`sim$gcHash`). This module uses an example from a region in Saskatchewan as a default simulation and can be modified to run independently (i.e., just for translation of m3 to above ground carbon in the three pools).

##Units

The user provides growth curves of cumulative m3/ha over time for one leading species (following CBM-CFS3). Those curves are fed into the Boudewyn algorithms (CBM_vol2biomass module) with its results multiplied by 0.5 to give carbon/ha. This deck of modules simulates on an annual basis and it is preferable that the cumulative curves of m3/ha be provided over individual years. If these are not per individual years, the GAM fitted values should be modified to provide yearly fitted.values. The object cumPoolsRaw (line 411) in CBM_vol2biomass.R, is the cumulative values for each of the three above-ground live pools in tonnes of carbon/ha. All following values are in tonnes of c/ha.


##Output

This module provides the `sim$growth_increments` and its hashed version, ` sim$gcHash` available for the spadesCBMcore module. All other output created by this module is for visual checks of the growth curve themselves and their processing.

##SpaDES

There is only one event in this module (init), and this module is only scheduled once. This module is designed to be part of SpaDES-deck spadesCBM, SpaDES modules representing CBM-CFS3, but transparent and spatialized. There are four modules in this family: spadesCBMdefaults, spadesSBMinputs, CBM_vol2biomass, and spadesCBMcore.

##list of potential improvements

* add a check to see if the growth curves provided are on an annual basis and if not, modify the GAM outputs to provided and annual fitted value.
* make k (knots in the GAMs) a user defined parameter
* provide an option to fit a GAM prior to the maximum value of each curve (from 0 to max) with its own number of knots (k) and one for after the maximum value with possibly few knots.
* same as previous but for the weights going into the GAMs.


# Usage

```{r module_vol2biomass_usage, eval=FALSE}
library(SpaDES)
library(magrittr) # this is needed to use "%>%" below
moduleDir <- "C:/Celine/github/spadesCBM"
inputDir <- file.path(moduleDir, "inputs") %>% reproducible::checkPath(create = TRUE)
outputDir <- file.path(moduleDir, "outputs")
cacheDir <- file.path(outputDir, "cache")
times <- list(start = 0, end = 10)

parameters <- list(
  CBM_vol2biomass = list(.useCache = ".inputObjects")
  #.progress = list(type = "text", interval = 1), # for a progress bar
  ## If there are further modules, each can have its own set of parameters:
  #module1 = list(param1 = value1, param2 = value2),
  #module2 = list(param1 = value1, param2 = value2)
)

modules <- list("CBM_vol2biomass")
objects <- list(
  #userGcMetafileName <- c("/RIA2019/gcMetaRuns.csv"),
  #userGcM3 <- c("/RIA2019/gcRIAm3.csv")

)
paths <- list(
  cachePath = cacheDir,
  modulePath = moduleDir,
  inputPath = inputDir,
  outputPath = outputDir
)
options(
    rasterTmpDir = inputDir,
    reproducible.cachePath = cacheDir,
    spades.inputPath = inputDir,
    spades.outputPath = outputDir,
    spades.modulePath = moduleDir
  )

myBiomass <- simInit(times = times, params = parameters, modules = modules,
                 objects = objects)

myBiomassOut <- spades(myBiomass)
```



<!--chapter:end:modules/CBM_vol2biomass/CBM_vol2biomass.Rmd-->

---
title: "CBM_core"
author: ""
date: "19 January 2018"
output: pdf_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
pkgPath <- file.path("packages", version$platform,
                     paste0(version$major, ".", strsplit(version$minor, "[.]")[[1]][1]))
.libPaths(pkgPath)   ## need to include.side = TRUE to use bookdown and rmarkdown

# example R options set globally
options("width" = 60
        , repos = c(CRAN = "https://cran.rstudio.com")
        )

## knitr-related options
options(knitr.table.format = function() {
  if (knitr::is_latex_output())
    "latex" else "pipe"
})

options("knitr.graphics.rel_path" = FALSE)

rm(list = ls(all.names = TRUE))

# options(bookdown.post.latex = function(x) {
#   # substitute nonbreaking spaces in \texttt{} with normal spaces
#   m = gregexpr('\\\\texttt\\{[^}]+}', x)
#   regmatches(x, m) = lapply(regmatches(x, m), function(z) {
#     gsub('\\\\ ', ' ', z)
#   })
#   # only build a skeleton for the online version
#   if (Sys.getenv('BOOKDOWN_FULL_PDF', '') == 'false') return(bookdown:::strip_latex_body(
#     x, '\nThis PDF is only a skeleton. Please either read the free online HTML version, or purchase a hard-copy of this book.\n'
#   ))
#   # fix syntax highlighting:
#   # \FunctionTok{tufte:}\AttributeTok{:tufte_html: default} ->
#   # \FunctionTok{tufte::tufte_html:}\AttributeTok{ default}
#   x = gsub('(\\\\AttributeTok\\{[^:]+:)(})(\\\\FunctionTok\\{)(:[^:]+:)', '\\1\\4\\2\\3', x)
#   if (length(i <- grep('^\\\\begin\\{longtable\\}', x)) == 0) return(x)
#   i1 = bookdown:::next_nearest(i, which(x == '\\toprule'))
#   i2 = bookdown:::next_nearest(i, which(x == '\\endfirsthead'))
#   x[i1 - 1] = paste0(x[i1 - 1], '\n\\begin{tabular}{', gsub('[^lcr]', '', gsub('.*\\[]', '', x[i])), '}')
#   x[i] = '\\begin{table}'
#   x[x == '\\end{longtable}'] = '\\end{tabular}\n\\end{table}'
#   x[x == '\\endhead'] = ''
#   x = x[-unlist(mapply(seq, i1, i2, SIMPLIFY = FALSE))]
#   x
# })

# chunk options set globally
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60),
  size = "tiny",
  fig.pos = "H",
  out.extra = ""
)



```

# Overview

NPP: Net primary productivity is for both above and below ground productivity. Provide an overview of what the module does / how to use the module.

Module documentation should be written so that others can use your module. This is a template for module documentation, and should be changed to reflect your module.

## R Markdown

R Markdown syntax allows R code, outputs, and figures to be rendered in the documentation.

For help writing in R Markdown, see <http://rmarkdown.rstudio.com/>.

# Usage

```{r module_core_usage, eval=FALSE}
library(igraph)
library(SpaDES.core)

moduleDir <- file.path(".")
inputDir <- file.path(moduleDir, "inputs") %>% reproducible::checkPath(create = TRUE)
outputDir <- file.path(moduleDir, "outputs")
cacheDir <- file.path(outputDir, "cache")
times <- list(start = 1990.00, end = 1994.00)
parameters <- list(
  CBM_core = list(.useCache = ".inputObjects")
  #.progress = list(type = "text", interval = 1), # for a progress bar
  ## If there are further modules, each can have its own set of parameters:
  #module1 = list(param1 = value1, param2 = value2),
  #module2 = list(param1 = value1, param2 = value2)
)
modules <- list("CBM_core")
objects <- list()
paths <- list(
  cachePath = cacheDir,
  modulePath = moduleDir,
  inputPath = inputDir,
  outputPath = outputDir
)

myCore <- simInit(times = times, params = parameters, modules = modules,
                 objects = objects, paths = paths)

outCore <- spades(myCore, debug = TRUE)
```

# Events

Describe what happens for each event type.

## Plotting

Write what is plotted.

## Saving

Write what is saved.

# Data dependencies

## Input data

How to obtain input data, and a description of the data required by the module. If `sourceURL` is specified, `downloadData("CBM_core", "path/to/modules/dir")` may be sufficient.

## Output data

Description of the module outputs.

# Links to other modules

Describe any anticipated linkages to other modules.

<!--chapter:end:modules/CBM_core/CBM_core.Rmd-->

